{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premium-simulation",
   "metadata": {},
   "source": [
    "# 6-1. 들어가며\n",
    "\n",
    "### 인공지능은 객관적일까?\n",
    "\n",
    "인공지능이 우리의 삶에 얼마나 가까이 다가왔을까요?\n",
    "오늘 하루를 떠올려 보면, 우리는 아마도 인공지능이 추천해주는 음악을 듣고, 뉴스 기사와 영화를 보았을 것입니다. 최근에는 인공지능 기반의 채용 시스템을 도입하는 곳도 늘고 있습니다. 대출 등 금융권에서도, 산업 현장에서도 활용되고 있습니다. 이처럼 인공지능이 사람의 의사결정을 돕는 사례가 늘고 있는데, 우리는 과연 인공지능을 온전히 믿을 수 있을까요?\n",
    "\n",
    "잘못된 머신러닝 학습에 대한 유명한 사례로 차량 충돌 사고 실험이 있습니다.\n",
    "한 데이터 제조업체에서 충돌 실험을 통해 탑승자의 신체 움직임을 파악하고 안전성을 높이고자 했습니다. 그러나 결과적으로 여성 탑승자가 남성 탑승자에 비해 사망률이 높았다고 합니다. 왜 그런 걸까요? 차량 실험에서 쓰인 데이터가 남성 위주였기 때문입니다.\n",
    "데이터로부터 편향성이 생긴 경우입니다.\n",
    "\n",
    "이뿐만이 아닙니다. 객관적일 것이라고 기대했던 인공지능이 오히려 인종, 성 차별적인 특성을 보이는 사례가 있습니다. 아마존에서 지원자의 이력서를 검토해 인재를 발굴해낼 수 있는 인공지능 채용 시스템을 개발해 왔습니다. 그러나 이 시스템에는 문제가 있었습니다.\n",
    "이력서에 '여성'이라는 단어가 포함되면 감점이 된다든지, 여자 대학을 졸업한 지원자의 점수가 감점이 된다든지 하는 식으로 여성에 대해 차별하는 것이 드러났습니다. 지난 10년간의 회사에 제출된 이력서 패턴을 익힌 인공지능 채용 시스템은 남성 우위인 기술산업 업계의 현실을 반영하게 된 것입니다.\n",
    "\n",
    "또 다른 사례가 있습니다.\n",
    "콤파스라는 범죄자의 형량을 정하는 알고리즘이 있습니다. 이 알고리즘은 범죄 방식, 생활 방식, 성격, 태도 등의 점수를 환산해 범죄자의 재범률을 예측하는 시스템입니다. 인종을 변수로 포함하고 있지 않은데도 흑인의 재범 가능성을 백인보다 2배 위험하다고 판단했습니다.\n",
    "엠아이티 테크놀로지 리뷰에 따르면 흑인과 백인은 동일 범행에 대해 다른 처벌을 받았기 때문에 이런 결과가 나타난 것입니다. 즉, 재범을 저지른 흑인은 체포될 확률일 백인에 비해 높았기 때문에 이런 데이터로 학습한 콤파스는 인종 차별을 할 수밖에 없었습니다.\n",
    "\n",
    "https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/\n",
    "\n",
    "데이터 안에 이미 편향성이 내재되어 있다면 이를 통해 나온 결과도 편향성을 가질 수밖에 없다는 것을 잘 보여주는 사례들입니다.\n",
    "\n",
    "데이터를 기반으로 하는 인공지능에 대해 생각해봅시다. 만약 우리가 가진 데이터가 이미 편향되어 있다면 이를 이용하여 만든 알고리즘 또한 편향될 확률이 매우 높습니다. 그래서 최근에는 인공지능이 가진 편향성을 예방하기 위한 연구가 지속되고 있습니다. 특히 자연어처리 분야, 그중에서도 워드 임베딩과 관련된 연구가 많이 이루어지고 있습니다.\n",
    "\n",
    "왜 그럴까요? 몇 가지 이유를 생각해 볼 수 있는데요. 우선 언어의 사용패턴이 담긴 코퍼스야말로 인간 무의식 속에 감추어진 편향성이 고스란히 드러나는 데이터셋이기 때문입니다. 그리고 그 언어의 의미가 워드 임베딩에 추상적인 형태로 담겨 있으며, 최근 연구를 통해 그 임베딩 공간에서 편향성을 정량적으로 측정하는 방법론들이 발표되면서, 이 분야의 연구가 활기를 띠게 되었기 때문입니다.\n",
    "\n",
    "그래서 오늘은 워드 임베딩에 숨어 있는 편향성을 측정하는 대표적인 방법론인 Word Embedding Association Test (WEAT)라는 기법에 대해 알아보고, 이를 활용해서 우리가 학습시킨 Word2Vec 임베딩 내의 편향성을 측정해 보면서, 실제로 이 방법론이 우리 머리 속에 있는 편향성을 잘 반영하는지도 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-large",
   "metadata": {},
   "source": [
    "### 학습 목표\n",
    "\n",
    "데이터의 편향성에 대한 문제의식을 갖는다.\n",
    "임베딩 모델의 편향성을 체크하는 방법 중 하나인 Word Embedding Association Test (WEAT)를 알아본다.\n",
    "WEAT 수식의 의미를 이해하고 이를 구현해본다.\n",
    "pre-train된 모델을 불러와서 WEAT score를 구해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-difference",
   "metadata": {},
   "source": [
    "### 목차\n",
    "\n",
    "1.워드 임베딩의 편향성\n",
    "2.WEAT를 통한 편향성 측정\n",
    "3.WEAT 구현하기\n",
    "4.사전학습된 Word Embedding에 WEAT 적용\n",
    "5.직접 만드는 Word Embedding에 WEAT 적용(1)\n",
    "6.직접 만드는 Word Embedding에 WEAT 적용(2)\n",
    "7.프로젝트 : 모든 장르 간 편향성 측정해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-vessel",
   "metadata": {},
   "source": [
    "# 6-2. 워드 임베딩의 편향성\n",
    "\n",
    "### 워드 임베딩 속의 편향성\n",
    "\n",
    "프로그래머라는 단어에서 남성의 이미지가, 가정주부라는 단어에서 여성의 이미지가 떠오르시나요? 분명 프로그래머와 가정주부는 젠더 중립적인 단어임에도 불구하고 우리의 무의식 속에서 어쩌면 정말 그렇게 느끼고 있을지도 모르겠군요.\n",
    "\n",
    "![image1](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-3-P-01.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-contribution",
   "metadata": {},
   "source": [
    "위 그림은 2016년에 발표된 Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings라는 제목의 논문에 포함된 것입니다. 이 논문의 저자는 학습된 Word Embedding을 2차원으로 차원 축소해서 시각화했을 때, 분명히 젠더 중립적인 단어임에도 불구하고 Programmer, Doctor, Engineer 등의 단어는 남성대명사 He에 가깝게, Homemaker, Nurse, Hairdresser 등의 단어는 여성대명사 She에 가깝게 위치하는 것을 보여 줌으로써 큰 반향을 불러일으켰습니다. 워드 임베딩 속 벡터들에는 어쩌면 우리가 가지고 있을지도 모를 편견을 고스란히 반영되어 있었다는 것을 보여 주었기 때문입니다.\n",
    "\n",
    "https://arxiv.org/pdf/1607.06520.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-happening",
   "metadata": {},
   "source": [
    "#### WEAT(Word Embedding Association Test)\n",
    "\n",
    "그런데 워드 임베딩 벡터들 간에는 의미적인 유사도 거리를 정량적으로 측정할 수 있습니다. 그렇다면 워드 임베딩에 내포된 편향성도 정량적으로 측정할 방법은 없을까요?\n",
    "위 논문이 발표되자마자 몇 달도 되지 않아 그런 방법이 제안되었습니다.\n",
    "\n",
    "Word Embedding Association Test (WEAT)는 임베딩 모델의 편향을 측정하는 방식 중 하나로, 2016년에 Aylin Caliskan이 제안했습니다.\n",
    "\n",
    "논문 원본 : Semantics derived automatically from language corpora necessarily contain human biases\n",
    "https://arxiv.org/pdf/1608.07187.pdf\n",
    "\n",
    "과연 편향이라는 것을 어떻게 정량적으로 정의할 수 있을까요? 한번 남자(Male)가 Scientist에, 여자(Female)가 Art에 가깝다라는 편향을 Word Embedding 상에서 정의하는 방법을 생각해 봅시다. 만약 Science와 Art가 모두 완벽히 젠더 중립적이라면, Word Embedding 상에서도 Science, Art가 Male, Female 두 단어와의 거리가 동일해야 할 것입니다. 그러나 만약 정말 편향이 존재한다면… 그땐 Science와 Male 간의 거리가 Science와 Female 간의 거리보다 가깝고, 거꾸로 Art와 Male 간의 거리는 Art와 Female간의 거리보다 멀어야겠죠?\n",
    "우리는 워드 임베딩 간의 거리를 코사인 유사도로 계산할 수 있다는 것을 이미 알고 있으니, 그런 방식으로 계산해 보면 편향성을 쉽게 구할 수 있을 것 같습니다! 아주 간단한 아이디어죠?\n",
    "\n",
    "그런데, 고작 4개의 단어 사이의 거리를 계산하는 방식으로 워드 임베딩 공간상에 편향이 존재한다고 단정할 수 있을까요? 어쩌면 그저 우연히 수치가 그렇게 나타났을 뿐일 수 있지 않을까요?\n",
    "그래서 WEAT는 Male과 Female, Science와 Art라는 개념을 가장 잘 대표하는 단어들을 여러 개 골라 단어 셋(set)을 만듭니다. 그래서 단어 셋에 속한 모든 단어들끼리의 편향성을 전부 계산해서 평균수치화 해보면보다 명확하게 개념적인 편향성이 존재함을 밝힐 수 있지 않을까요?\n",
    "\n",
    "이러한 단어 셋을 WEAT에서는 각각 target과 attribute라고 합니다.\n",
    "\n",
    "위의 예를 다시 들자면, Science를 대표하는 target 단어 셋 X와 Art를 대표하는 target 단어 셋 Y가 있다고 하면 X-Y 셋을 통한 개념축 하나가 얻어집니다.\n",
    "그리고 Male을 대표하는 attribute 단어 셋 A와 Female을 대표하는 attribute 단어 셋 B가 있다면 A-B 셋을 통한 개념축 하나가 또 얻어집니다.\n",
    "편향성이 없다면, X에 속한 단어들은 A에 속한 단어들과의 거리나 B에 속한 단어들과의 거리가 별 차이가 없어야 합니다. 반대의 경우라면 뚜렷하게 차이가 나겠죠. Y의 경우도 마찬가지입니다.\n",
    "\n",
    "다음 스텝에 수식을 통해 보다 명확하게 설명할 WEAT score는 바로 위와 같은 방식으로 계산된 수치입니다. 절댓값이 클수록 두 개념축 사이의 편향성이 크게 나타나는 것으로 해석됩니다.\n",
    "\n",
    "(참고)\n",
    "WEAT 개념의 아이디어는 심리학의 IAT(Implicit Association Test)라는 인지편향성 실험 구조에서 따온 것입니다. IAT는 WEAT처럼 X-Y, A-B 두 개념축을 설정하는 점에서는 동일합니다. 다만 단어들 사이의 거리를 측정하는 방법이 워드 임베딩간 코사인 유사도를 계산하는 방식이 아니라, 피실험자들에게 전자적으로 단어 연상 실험을 하면서 응답 반응 속도를 측정하는 방식을 사용했을 뿐입니다. 매우 재미있는 아이디어이므로 혹시 심리학에 관심이 있으시다면 아래 링크를 열어 보시면 실제로 IAT 테스트를 수행해서 본인 무의식 속에 있는 편향성을 측정해볼 수도 있습니다.\n",
    "\n",
    "IAT 홈페이지 : Project Implicit\n",
    "https://implicit.harvard.edu/implicit/education.html\n",
    "아래 표는 구글의 테크블로그에서 WEAT 개념을 소개하면서 첨부한 실험 결과표입니다.\n",
    "\n",
    "Text Embedding Models Contain Bias. Here's Why That Matters\n",
    "https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html\n",
    "\n",
    "![image2](https://4.bp.blogspot.com/-KHaWu25QTnY/WtEARsgv0uI/AAAAAAAAFDY/Rx6WdfTYT-sq2_IU9uBX_Tfzb35pWJp2gCLcBGAs/s1600/WEAT_table_1600_ppi.png)\n",
    "\n",
    "표에서 파란색은 사람의 편향과 같은 경우이고, 노란색은 사람의 편향과 반대인 경우를 의미합니다. (사람이 가진 편향은 Implicit Association Tests로 측정했습니다.)\n",
    "대부분의 색이 파란색인 것을 볼 수 있습니다. 이 표가 또한 말해주는 것은, 사람이 가진 편향이 자연어 코퍼스 데이터에 반영되어있고, 이 데이터로 만든 워드 임베딩 모델은 그 편향을 내재할 수밖에 없다는 점입니다.\n",
    "\n",
    "꽃과 벌레, 유쾌함과 불쾌함 등 누구나 동의할만한 편향성이 존재하는 경우엔 대부분의 경우 WEAT score의 절댓값이 1.5 이상으로 뚜렷한 편향성 수치가 나오는 것을 볼 수 있습니다. 그 외 다양한 개념축간 편향성이 존재하는 것도 흥미롭게 살펴볼 수 있습니다.\n",
    "\n",
    "그리고 Glove, Word2Vec 등 다양한 워드 임베딩 모델에 대해 동일한 실험을 하여 WEAT score를 측정해 본 결과도 흥미롭습니다. 모델마다 WEAT score가 동일하게 나오는 것이 아닙니다. 이런 차이점의 원인을 분석해 보는 것도 흥미로울 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-treat",
   "metadata": {},
   "source": [
    "### 6-3. WEAT를 통한 편향성 측정\n",
    "\n",
    "WEAT score는 다음과 같이 정의합니다.\n",
    " \n",
    "얼핏 복잡해 보이지만 WEAT score를 계산하기 위한 식을 하나씩 살펴봅시다.\n",
    "\n",
    "이 테스트는 두 벡터의 유사도를 측정하기 위해 cosine similarity를 이용합니다.\n",
    "cosine similarity는 두 벡터 사이의 cosine 값을 이용하여 두 벡터의 유사도를 측정합니다.\n",
    "다시 말해, 두 벡터 가 주어졌을 때, cosine similarity 는 dot product와 magnitude를 사용하여 구할 수 있습니다.\n",
    "\n",
    "![image3]()\n",
    "\n",
    "\n",
    " 두 벡터의 방향이 똑같을 때\n",
    " 두 벡터가 직교할 때\n",
    " 두 벡터의 방향이 반대일 때\n",
    "cosine similarity는 -1에서 1을 가질 수 있으며 두 벡터의 방향이 얼마나 유사한지를 나타내게 됩니다.\n",
    "\n",
    "벡터 \n",
    " 와 \n",
    "가 있을 때, \n",
    "는 벡터 \n",
    " 와 \n",
    "의 cosine similarity를 의미하므로,\n",
    "\n",
    "아래 식의 가 의미하는 것은 target에 있는 단어 가 두 attribute 셋 A, B에 속한 단어들과의 유사도의 평균(mean)값이 얼마나 차이 나는지를 측정합니다. 즉, 는 개별 단어 가 개념축 A-B에 대해 가지는 편향성을 계산한 값이 됩니다. 이 편향성 값은 -2에서 2사이의 값을 가지게 되며, 그 절댓값이 클수록 는 A-B 개념축에 대해 편향성을 가진다는 뜻이 됩니다.\n",
    "\n",
    "이제 맨 위에 소개했던 WEAT score의 정의로 되돌아가 봅시다.\n",
    "\n",
    " \n",
    "위 식의 분자 부분은 target X, Y에 속하는 각 단어 , 들이 개념축 A-B에 대해 가지는 편향성을 다시 평균 내서 뺀 차이에 해당합니다. 즉, X에 속하는 단어들과 Y에 속하는 단어들이 A-B 개념축에 대해 가지는 편향성의 정도가 뚜렷이 차이 날수록 이 WEAT score 식의 분자값의 절댓값은 커지게 됩니다. 이 값을 X, Y에 속하는 모든 단어들이 가지는 편향성 값의 표준편차(std)로 normalize한 값이 최종 WEAT score가 됩니다.\n",
    "\n",
    "설명이 좀 복잡했겠지만 다음 스텝에서 구현 예시를 통해 좀 더 명확히 이해해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-storm",
   "metadata": {},
   "source": [
    "### 6-4. WEAT 구현하기\n",
    "\n",
    "이제 WEAT score를 코드로 구현해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "permanent-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-filename",
   "metadata": {},
   "source": [
    "우선 두 개의 target 단어 셋 X, Y와 두 개의 attribute 단어 셋 A, B를 정의합니다.\n",
    "단어 셋을 정할 때는 두 개의 target 셋의 크기가 같아야 하고, 두 개의 attribute 셋의 크기가 같아야 합니다.\n",
    "\n",
    "targets\n",
    "A set(꽃) : 장미, 튤립, 백합, 데이지\n",
    "B set(곤충) : 거미, 모기, 파리, 메뚜기\n",
    "attributes\n",
    "X set(유쾌) : 사랑, 행복, 웃음\n",
    "Y set(불쾌) : 재난, 고통, 증오\n",
    "위 단어들의 임베딩 결과가 다음과 같다고 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "perfect-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_A = {\n",
    "    '장미': [4.1, 1.2, -2.4, 0.5, 4.1],\n",
    "    '튤립': [3.1, 0.5, 3.6, 1.7, 5.8],\n",
    "    '백합': [2.9, -1.3, 0.4, 1.1, 3.7],\n",
    "    '데이지': [5.4, 2.5, 4.6, -1.0, 3.6]\n",
    "}\n",
    "target_B = {\n",
    "    '거미': [-1.5, 0.2, -0.6, -4.6, -5.3],\n",
    "    '모기': [0.4, 0.7, -1.9, -4.5, -2.9],\n",
    "    '파리': [0.9, 1.4, -2.3, -3.9, -4.7],\n",
    "    '메뚜기': [0.7, 0.9, -0.4, -4.1, -3.9]\n",
    "}\n",
    "attribute_X = {\n",
    "    '사랑':[2.8,  4.2, 4.3,  0.3, 5.0],\n",
    "    '행복':[3.8,  3. , -1.2,  4.4, 4.9],\n",
    "    '웃음':[3.7, -0.3,  1.2, -2.5, 3.9]\n",
    "}\n",
    "attribute_Y = {\n",
    "    '재난': [-0.2, -2.8, -4.7, -4.3, -4.7],\n",
    "    '고통': [-4.5, -2.1,  -3.8, -3.6, -3.1],\n",
    "    '증오': [-3.6, -3.3, -3.5,  -3.7, -4.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bound-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.1  1.2 -2.4  0.5  4.1]\n",
      " [ 3.1  0.5  3.6  1.7  5.8]\n",
      " [ 2.9 -1.3  0.4  1.1  3.7]\n",
      " [ 5.4  2.5  4.6 -1.   3.6]]\n",
      "[[-1.5  0.2 -0.6 -4.6 -5.3]\n",
      " [ 0.4  0.7 -1.9 -4.5 -2.9]\n",
      " [ 0.9  1.4 -2.3 -3.9 -4.7]\n",
      " [ 0.7  0.9 -0.4 -4.1 -3.9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([v for v in target_A.values()])\n",
    "B = np.array([v for v in target_B.values()])\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opposed-packet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.8  4.2  4.3  0.3  5. ]\n",
      " [ 3.8  3.  -1.2  4.4  4.9]\n",
      " [ 3.7 -0.3  1.2 -2.5  3.9]]\n",
      "[[-0.2 -2.8 -4.7 -4.3 -4.7]\n",
      " [-4.5 -2.1 -3.8 -3.6 -3.1]\n",
      " [-3.6 -3.3 -3.5 -3.7 -4.4]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([v for v in attribute_X.values()])\n",
    "Y = np.array([v for v in attribute_Y.values()])\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-pressure",
   "metadata": {},
   "source": [
    "s('사랑', A, B) 를 계산해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southeast-provision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901751654626237\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(i, j):\n",
    "    return dot(i, j.T)/(norm(i)*norm(j))\n",
    "\n",
    "def s(w, A, B):\n",
    "    c_a = cos_sim(w, A)\n",
    "    c_b = cos_sim(w, B)\n",
    "    mean_A = np.mean(c_a, axis=-1)\n",
    "    mean_B = np.mean(c_b, axis=-1)\n",
    "    return mean_A - mean_B#, c_a, c_b\n",
    "\n",
    "print(s(attribute_X['사랑'], A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-flush",
   "metadata": {},
   "source": [
    "WEAT score값이 양수이므로, attribute_X에 있는 '사랑'이라는 단어는 target_B(곤충)보다 target_A(꽃)와 더 가깝다는 것을 알 수 있습니다.\n",
    "attribute_Y에 있는 '재난'과의 관계도 계산해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6691842929755343\n"
     ]
    }
   ],
   "source": [
    "print(s(attribute_Y['재난'], A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-vintage",
   "metadata": {},
   "source": [
    "위와 반대로 WEAT score가 음수가 나왔으므로, '재난'은 target_B와 더 가깝다는 것을 알 수 있습니다.\n",
    "\n",
    "그럼 attribute_X와 target_A, target_B 사의의 평균값, 그리고 attribute_Y와 target_A, target_B 사의의 평균값은 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cardiovascular-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37181942 0.41632807 0.21117431]\n",
      "0.333\n"
     ]
    }
   ],
   "source": [
    "print(s(X, A, B))\n",
    "print(round(np.mean(s(X, A, B)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-republican",
   "metadata": {},
   "source": [
    "attribute_X와 target_A, target_B 사이의 평균값은 0.333입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virgin-sheet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39609272 -0.37389852 -0.41242037]\n",
      "-0.394\n"
     ]
    }
   ],
   "source": [
    "print(s(Y, A, B))\n",
    "print(round(np.mean(s(Y, A, B)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-municipality",
   "metadata": {},
   "source": [
    "attribute_Y와 target_A, target_B 사이의 평균값은 -0.394입니다.\n",
    "\n",
    "그럼 이번에는 WEAT score의 수식 전체를 코드로 나타내 봅시다.\n",
    "\n",
    "[meanx∈Xs(x,A,B)−meany∈Ys(y,A,B)] / [stdw∈X∪Ys(w,A,B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modular-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97\n"
     ]
    }
   ],
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \n",
    "    s_X = s(X, A, B)\n",
    "    s_Y = s(Y, A, B)\n",
    "\n",
    "    mean_X = np.mean(s_X)\n",
    "    mean_Y = np.mean(s_Y)\n",
    "    \n",
    "    std_dev = np.std(np.concatenate([s_X, s_Y], axis=0))\n",
    "    \n",
    "    return  (mean_X-mean_Y)/std_dev\n",
    "\n",
    "print(round(weat_score(X, Y, A, B), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-count",
   "metadata": {},
   "source": [
    "WEAT score가 매우 높게 나온 것을 알 수 있습니다. 즉, 꽃은 유쾌한 단어와 상대적으로 가깝고, 곤충은 불쾌한 단어와 가깝다는 것을 수치적으로 확인할 수 있었습니다.\n",
    "\n",
    "이제 이를 시각적으로 확인해볼까요?\n",
    "PCA를 통해 5차원이었던 벡터를 2차원으로 줄여 그림을 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emotional-actress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8d78529a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pc_A = pca.fit_transform(A)\n",
    "pc_B = pca.fit_transform(B)\n",
    "pc_X = pca.fit_transform(X)\n",
    "pc_Y = pca.fit_transform(Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pc_A[:,0],pc_A[:,1], c='blue', label='A')\n",
    "ax.scatter(pc_B[:,0],pc_B[:,1], c='red', label='B')\n",
    "ax.scatter(pc_X[:,0],pc_X[:,1], c='skyblue', label='X')\n",
    "ax.scatter(pc_Y[:,0],pc_Y[:,1], c='pink', label='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-evolution",
   "metadata": {},
   "source": [
    "파란색 점(A)과 하늘색 점(X)이 가깝고, 빨간색 점(B)과 분홍색 점(Y)이 가깝게 표현된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-burner",
   "metadata": {},
   "source": [
    "### 6-5. 사전학습된 Word Embedding에 WEAT 적용\n",
    "\n",
    "지금까지 WEAT가 어떻게 계산되는지 확인해보았습니다. 이제 실제 pretrain된 임베딩 모델을 이용하여 계산해볼까요?\n",
    "\n",
    "\n",
    "구글에서 학습한 모델을 사용해보도록 하겠습니다.\n",
    "\n",
    "우선 ~/aiffel/weat 폴더를 만들고 모델을 다운받아 ~/aiffel/weat 경로에 옮겨 주세요. 압축을 풀면 대략 3G 정도 됩니다.\n",
    "(❗대용량 다운로드이기에 15분정도 소요됩니다.)\n",
    "\n",
    "GoogleNews-vectors-negative300.bin.gz\n",
    "https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download\n",
    "\n",
    "$ mkdir -p ~/aiffel/weat\n",
    "$ cd ~/aiffel/weat\n",
    "$ gzip -d GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "그리고 다음 코드에서 data_dir 변수에 본인의 경로를 잘 설정해서 모델을 불러오도록 합니다.\n",
    "\n",
    "$ pip install gensim\n",
    "\n",
    "💡 참고\n",
    "w2v를 사용하다가 메모리 부족이 발생할 수 있습니다. 이때는 워드 임베딩 내 300만 개의 단어 중 자주 쓰는 단어 50만 개만 꺼내어 사용하도록 아래와 같이 limit 파라미터값을 주면 메모리 사용량을 크게 줄일 수 있습니다.\n",
    "\n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "resistant-english",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj25/anaconda3/envs/aiffel-nlp/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '~/aiffel/weat' \n",
    "model_dir = os.path.join(data_dir, 'GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 50만개의 단어만 활용합니다. 메모리가 충분하다면 limit 파라미터값을 생략하여 300만개를 모두 활용할 수 있습니다. \n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "careful-momentum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f8d784801d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-worse",
   "metadata": {},
   "source": [
    "w2v에 있는 단어 개수와 벡터 크기를 살펴볼까요?\n",
    "\n",
    "💡 참고\n",
    "2021년 3월, Gensim이 4.0 으로 버전업되면서 KeyedVectors에 vocab dict가 제거되었습니다. 상세한 내용은 아래 링크를 참고해 주세요.\n",
    "\n",
    "Migrating from Gensim 3.x to 4\n",
    "https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "republican-currency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "300\n",
      "(500000, 300)\n"
     ]
    }
   ],
   "source": [
    "# print(len(w2v.vocab))   # Gensim 3.X 버전까지는 w2v.vocab을 직접 접근할 수 있습니다. \n",
    "print(len(w2v.index_to_key))   # Gensim 4.0부터는 index_to_key를 활용해 vocab size를 알 수 있습니다. \n",
    "print(len(w2v['I']))                    # 혹은 단어를 key로 직접 vector를 얻을 수 있습니다. \n",
    "print(w2v.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-telephone",
   "metadata": {},
   "source": [
    "w2v에는 limit으로 지정한 갯수(디폴트는 3,000,000개)의 단어가 있고, 각 단어는 300차원을 갖는다는 것을 알 수 있습니다.\n",
    "\n",
    "'happy'라는 단어의 벡터를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "referenced-illinois",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.18798828e-04,  1.60156250e-01,  1.60980225e-03,  2.53906250e-02,\n",
       "        9.91210938e-02, -8.59375000e-02,  3.24218750e-01, -2.17285156e-02,\n",
       "        1.34765625e-01,  1.10351562e-01, -1.04980469e-01, -2.90527344e-02,\n",
       "       -2.38037109e-02, -4.02832031e-02, -3.68652344e-02,  2.32421875e-01,\n",
       "        3.20312500e-01,  1.01074219e-01,  5.83496094e-02, -2.91824341e-04,\n",
       "       -3.29589844e-02,  2.11914062e-01,  4.32128906e-02, -8.59375000e-02,\n",
       "        2.81250000e-01, -1.78222656e-02,  3.79943848e-03, -1.71875000e-01,\n",
       "        2.06054688e-01, -1.85546875e-01,  3.73535156e-02, -1.21459961e-02,\n",
       "        2.04101562e-01, -3.80859375e-02,  3.61328125e-02, -8.15429688e-02,\n",
       "        8.44726562e-02,  9.37500000e-02,  1.44531250e-01,  7.42187500e-02,\n",
       "        2.51953125e-01, -7.91015625e-02,  8.69140625e-02,  1.58691406e-02,\n",
       "        1.09375000e-01, -2.23632812e-01, -5.15747070e-03,  1.68945312e-01,\n",
       "       -1.36718750e-01, -2.51464844e-02, -3.85742188e-02, -1.33056641e-02,\n",
       "        1.38671875e-01,  1.76757812e-01,  1.10351562e-01,  1.51367188e-01,\n",
       "        7.86132812e-02, -1.69921875e-01,  1.20605469e-01, -4.37500000e-01,\n",
       "       -4.32128906e-02,  1.34765625e-01, -3.45703125e-01,  9.13085938e-02,\n",
       "        4.71191406e-02,  9.66796875e-02, -1.61132812e-02, -4.71191406e-02,\n",
       "       -4.68750000e-02,  1.37695312e-01,  9.96093750e-02,  4.49218750e-02,\n",
       "       -2.49023438e-02,  1.58203125e-01, -3.57421875e-01, -1.21093750e-01,\n",
       "        1.15722656e-01,  9.08203125e-02,  1.40625000e-01,  1.60156250e-01,\n",
       "       -4.42504883e-03,  5.34667969e-02,  2.28515625e-01,  1.88476562e-01,\n",
       "       -3.88183594e-02, -2.53906250e-01, -1.74804688e-01,  9.81445312e-02,\n",
       "        1.08642578e-02,  1.41601562e-01,  7.81250000e-03,  1.36718750e-01,\n",
       "       -2.08007812e-01, -3.41796875e-02, -2.50000000e-01,  1.25976562e-01,\n",
       "        1.57226562e-01,  3.31115723e-03, -1.51367188e-01, -6.98242188e-02,\n",
       "       -1.40625000e-01,  2.06054688e-01, -3.54003906e-02,  1.57226562e-01,\n",
       "        5.83496094e-02, -3.58886719e-02,  2.12890625e-01, -1.13769531e-01,\n",
       "        1.41601562e-01, -1.29394531e-02,  9.13085938e-02, -3.95507812e-02,\n",
       "        9.76562500e-02, -2.69775391e-02,  1.30004883e-02, -1.30859375e-01,\n",
       "        3.32031250e-01, -3.53515625e-01, -5.44433594e-02, -2.50244141e-02,\n",
       "       -1.42578125e-01,  6.49414062e-02,  5.54199219e-02, -4.83398438e-02,\n",
       "       -1.12304688e-01, -1.32812500e-01, -6.73828125e-02, -1.41601562e-01,\n",
       "       -2.05078125e-01, -1.29882812e-01, -1.04003906e-01, -8.10546875e-02,\n",
       "       -1.67968750e-01,  1.63085938e-01, -1.13769531e-01, -5.17578125e-02,\n",
       "        7.61718750e-02,  3.59375000e-01,  1.04003906e-01,  3.59375000e-01,\n",
       "       -8.74023438e-02,  6.54296875e-02, -1.09863281e-02, -1.88476562e-01,\n",
       "       -6.59179688e-02,  2.30468750e-01, -2.96875000e-01,  6.59179688e-03,\n",
       "        1.49414062e-01, -1.73828125e-01,  1.31835938e-01,  2.36328125e-01,\n",
       "       -9.22851562e-02,  1.70898438e-01, -1.70898438e-02,  3.12500000e-02,\n",
       "       -3.37219238e-03,  9.66796875e-02, -2.61718750e-01, -1.84326172e-02,\n",
       "       -1.85546875e-01,  1.24023438e-01,  3.00781250e-01,  2.43164062e-01,\n",
       "        3.06640625e-01, -3.28125000e-01, -5.05371094e-02,  1.01562500e-01,\n",
       "        7.86132812e-02, -1.44531250e-01, -1.25976562e-01, -2.41699219e-02,\n",
       "        2.94921875e-01, -1.50390625e-01, -3.97949219e-02,  2.75390625e-01,\n",
       "        1.26953125e-01, -9.86328125e-02, -1.39648438e-01,  2.52685547e-02,\n",
       "       -8.54492188e-02, -1.72119141e-02,  9.17968750e-02,  1.39648438e-01,\n",
       "       -2.39257812e-01, -2.11914062e-01, -2.21679688e-01,  1.53320312e-01,\n",
       "       -1.58691406e-02, -2.00195312e-01, -2.07519531e-02,  3.58886719e-02,\n",
       "       -6.96629286e-07, -2.13867188e-01,  2.00195312e-01, -1.09375000e-01,\n",
       "       -5.15136719e-02,  6.22558594e-02, -3.22265625e-01, -7.86132812e-02,\n",
       "        5.02929688e-02,  7.08007812e-02,  1.20117188e-01, -1.79687500e-01,\n",
       "        1.59179688e-01, -1.02233887e-03, -3.49609375e-01,  1.25000000e-01,\n",
       "        6.44531250e-02,  8.10546875e-02, -3.39355469e-02,  7.42187500e-02,\n",
       "       -3.08837891e-02, -1.38671875e-01, -3.19824219e-02,  1.99218750e-01,\n",
       "        1.25000000e-01,  5.68847656e-02, -1.67968750e-01,  1.30859375e-01,\n",
       "        2.90527344e-02, -1.49536133e-02, -1.39648438e-01,  4.07714844e-02,\n",
       "       -1.05590820e-02, -1.74804688e-01,  2.12890625e-01, -1.41601562e-01,\n",
       "        2.30712891e-02, -3.36914062e-02, -8.78906250e-02, -6.64062500e-02,\n",
       "       -6.93359375e-02, -7.42187500e-02,  7.03125000e-02, -2.01416016e-02,\n",
       "       -1.26953125e-01, -3.63769531e-02,  5.93261719e-02,  1.18164062e-01,\n",
       "       -6.34765625e-03, -7.42187500e-02,  3.19824219e-02,  6.68945312e-02,\n",
       "       -2.27539062e-01,  6.54296875e-02,  1.79443359e-02,  1.46484375e-01,\n",
       "       -5.49316406e-02, -1.15234375e-01, -2.16796875e-01,  8.74023438e-02,\n",
       "        2.61718750e-01,  1.54296875e-01,  6.71386719e-03, -2.78320312e-02,\n",
       "       -4.15039062e-03, -2.09960938e-02, -5.51757812e-02, -9.76562500e-03,\n",
       "       -1.29882812e-01,  1.31835938e-01, -8.42285156e-03,  2.29492188e-01,\n",
       "        1.78710938e-01,  1.94335938e-01,  4.68750000e-02,  2.18505859e-02,\n",
       "       -2.75878906e-02,  1.73828125e-01,  1.33789062e-01,  1.36718750e-01,\n",
       "        3.10546875e-01,  9.39941406e-03,  9.22851562e-02, -2.44140625e-01,\n",
       "       -5.10253906e-02,  7.81250000e-02, -1.43554688e-01,  9.17968750e-02,\n",
       "        2.96630859e-02,  9.46044922e-03, -2.04101562e-01,  1.60156250e-01,\n",
       "        1.43554688e-01, -2.02636719e-02,  2.13623047e-02, -6.98242188e-02,\n",
       "       -3.11279297e-03, -2.52685547e-02, -1.09863281e-01,  1.07910156e-01,\n",
       "       -7.03125000e-02, -1.27929688e-01, -5.07812500e-02,  4.27246094e-02,\n",
       "       -7.32421875e-02, -3.54003906e-02,  8.88671875e-02, -3.02734375e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-bride",
   "metadata": {},
   "source": [
    "'happy'와 가장 유사한 단어를 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "buried-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049172401428),\n",
       " ('satisfied', 0.6437949538230896),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.6272379159927368),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665882110596)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['happy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-turkey",
   "metadata": {},
   "source": [
    "다른 단어들도 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demanding-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relatives', 0.6662651896476746),\n",
       " ('familiy', 0.6517067551612854),\n",
       " ('families', 0.6252894401550293),\n",
       " ('siblings', 0.6140850186347961),\n",
       " ('friends', 0.6128395199775696),\n",
       " ('mother', 0.6065612435340881),\n",
       " ('aunt', 0.5811319351196289),\n",
       " ('grandparents', 0.5762072205543518),\n",
       " ('father', 0.5717043876647949),\n",
       " ('Family', 0.5672314763069153)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-privilege",
   "metadata": {},
   "source": [
    "오타로 추정되는 몇몇 단어도 보입니다.\n",
    "이 단어들도 데이터 자체에 자주 나왔기 때문에 단어 셋에 포함되었다고 생각할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "direct-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elementary', 0.7868632078170776),\n",
       " ('schools', 0.7411909103393555),\n",
       " ('elementary_schools', 0.6597153544425964),\n",
       " ('kindergarten', 0.6529810428619385),\n",
       " ('eighth_grade', 0.6488089561462402),\n",
       " ('School', 0.6477997899055481),\n",
       " ('teacher', 0.63824063539505),\n",
       " ('students', 0.6301523447036743),\n",
       " ('classroom', 0.628162145614624),\n",
       " ('Schools', 0.6172095537185669)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['school'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-modem",
   "metadata": {},
   "source": [
    "어떤가요? 이 모델이 단어의 의미를 담은 벡터로 변환이 잘 되었다고 생각하나요?\n",
    "\n",
    "이제 WEAT를 통해 이 모델의 편향성을 확인해보도록 하겠습니다.\n",
    "논문에 있던 단어 셋으로 구성해보겠습니다.\n",
    "https://arxiv.org/pdf/1608.07187.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diagnostic-rally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4821917"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_A = ['science', 'technology', 'physics', 'chemistry', 'Einstein', 'NASA', 'experiment', 'astronomy']\n",
    "target_B = ['poetry', 'art', 'Shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "attribute_X = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_Y = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "A = np.array([w2v[word] for word in target_A])\n",
    "B = np.array([w2v[word] for word in target_B])\n",
    "X = np.array([w2v[word] for word in attribute_X])\n",
    "Y = np.array([w2v[word] for word in attribute_Y])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-crest",
   "metadata": {},
   "source": [
    "과학과 관련된 단어가 남성과 관련된 단어와 가깝고, 예술과 관련된 단어가 여성과 관련된 단어와 가깝게 나타났습니다.\n",
    "사람의 편향성을 실험하는 IAT에서도 이와 같게 나타났었습니다.\n",
    "많은 사람이 가진 편향이 임베딩 모델에 반영되었다고 볼 수 있습니다.\n",
    "\n",
    "이제 다른 셋을 구성해볼까요?\n",
    "두 개의 target 셋과 두 개의 attribute 셋을 다음과 같이 구성했습니다.\n",
    "target_A는 인스턴트 식품들로 단어를 구성하였고 target_B는 그 반대로 구성했습니다.\n",
    "attribute_X는 인스턴트를 의미하는 단어들로, attributes_Y는 그 반대로 구성했습니다.\n",
    "\n",
    "이 단어 셋들을 보면 target_A는 attribute_X와 attribute_Y 중 어떤 것과 가깝다고 생각하시나요?\n",
    "보통 target_A와 attribute_X가 가깝고, traget_B는 attribute_Y와 가깝다고 대답할 것입니다.\n",
    "임베딩 모델도 그렇게 생각할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "latter-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6929383"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_A = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_B = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_X = ['junk', 'canned', 'convenience', 'frozen', 'fast']\n",
    "attribute_Y = ['health', 'beneficial', 'good', 'nourishing', 'nutritious']\n",
    "\n",
    "A = np.array([w2v[word] for word in target_A])\n",
    "B = np.array([w2v[word] for word in target_B])\n",
    "X = np.array([w2v[word] for word in attribute_X])\n",
    "Y = np.array([w2v[word] for word in attribute_Y])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-expression",
   "metadata": {},
   "source": [
    "모델도 우리의 예상과 맞는 방향으로 상당히 높은 수치를 보이는 것을 확인했습니다.\n",
    "인스턴트 식품의 예시와 인스턴트를 의미하는 단어가 가까운 것은 당연합니다. 이 경우 모델이 편향되어있다기보다 단어의 의미를 잘 파악했다고 볼 수 있습니다.\n",
    "\n",
    "동일한 target 셋에 다른 attribute 셋을 만들볼까요?\n",
    "attribute_X에는 책과 관련된 단어로 구성하고, attribute_Y는 뉴스와 관련된 단어로 구성했습니다.\n",
    "이번에는 어떤 결과를 가져올까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "studied-virtue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.082050726"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_A = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_B = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_X = ['book', 'essay', 'dictionary', 'magazine', 'novel']\n",
    "attribute_Y = ['news', 'report', 'statement', 'broadcast', 'word']\n",
    "\n",
    "A = np.array([w2v[word] for word in target_A])\n",
    "B = np.array([w2v[word] for word in target_B])\n",
    "X = np.array([w2v[word] for word in attribute_X])\n",
    "Y = np.array([w2v[word] for word in attribute_Y])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-belief",
   "metadata": {},
   "source": [
    "굉장히 0에 가까운 결과를 보였습니다. 즉, 임베딩 모델이 판단하기에 어느 것끼리 가깝다고 말할 수 없는 것이지요.\n",
    "\n",
    "여러분이 target, attribute 셋을 만들어서 WEAT score를 구해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "heard-reception",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-deaae0ea6ae3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-deaae0ea6ae3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    target_B = [# TODO : 입력해 주세요!!]\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "target_A = [# TODO : 입력해 주세요!!]\n",
    "target_B = [# TODO : 입력해 주세요!!]\n",
    "attribute_X = [# TODO : 입력해 주세요!!]\n",
    "attribute_Y = [# TODO : 입력해 주세요!!]\n",
    "\n",
    "A = np.array([w2v[word] for word in target_A])\n",
    "B = np.array([w2v[word] for word in target_B])\n",
    "X = np.array([w2v[word] for word in attribute_X])\n",
    "Y = np.array([w2v[word] for word in attribute_Y])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conscious-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제 완료\n"
     ]
    }
   ],
   "source": [
    "#메모리를 다시 비워줍시다.\n",
    "del w2v\n",
    "print(\"삭제 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-disease",
   "metadata": {},
   "source": [
    "### 6-6. 직접 만드는 Word Embedding에 WEAT 적용(1)\n",
    "\n",
    "지금까지는 제시된 모델과 단어들로 WEAT score를 구해보았습니다.\n",
    "이제 주어진 데이터로 다음과 같은 과정을 수행해보도록 하겠습니다.\n",
    "\n",
    "형태소 분석기를 이용하여 품사가 명사인 경우, 해당 단어를 추출하기\n",
    "추출된 결과로 embedding model 만들기\n",
    "TF/IDF로 해당 데이터를 가장 잘 표현하는 단어 셋 만들기\n",
    "embedding model과 단어 셋으로 WEAT score 구해보기\n",
    "\n",
    "1. 형태소 분석기를 이용하여 품사가 명사인 경우 해당 단어를 추출하기\n",
    "synopsis.txt(대략 17MB)에는 2001년부터 2019년 8월까지 제작된 영화들의 시놉시스 정보가 있습니다.\n",
    "(개봉된 영화 중 일부만 포함되어있습니다. 더 많은 영화 정보를 원하시면 KOBIS에서 확인하시기 바랍니다.)\n",
    "synopsis.txt의 일부를 읽어볼까요?\n",
    "\n",
    "synopsis.zip \n",
    "https://aiffelstaticprd.blob.core.windows.net/media/documents/synopsis.zip\n",
    "\n",
    "$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/synopsis.zip\n",
    "$ mv synopsis.zip ~/aiffel/weat\n",
    "$ cd ~/aiffel/weat && unzip synopsis.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "based-gazette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사운드 엔지니어 상우(유지태 분)는 치매에 걸린 할머니(백성희 분)와\n",
      " 젊은 시절 상처한 한 아버지(박인환 분), 고모(신신애 분)와 함께 살고 있다.\n",
      " 어느 겨울 그는 지방 방송국 라디오 PD 은수(이영애 분)를 만난다.\n",
      " 자연의 소리를 채집해 틀어주는 라디오 프로그램을 준비하는 은수는 상우와 녹음 여행을 떠난다.\n",
      " 자연스레 가까워지는 두 사람은 어느 날, 은수의 아파트에서 밤을 보낸다.\n",
      " 너무 쉽게 사랑에 빠진 두 사람... 상우는 주체할 수 없을 정도로 그녀에게 빨려든다.\n",
      " 그러나 겨울에 만난 두 사람의 관계는 봄을 지나 여름을 맞이하면서 삐걱거린다.\n",
      " 이혼 경험이 있는 은수는 상우에게 결혼할 생각이 없다며 부담스러운 표정을 내비친다.\n",
      " \"어떻게 사랑이 변하니?...\"라고 묻는 상우에게 은수는 그저 \"헤어져\" 라고 단호하게 말한다.\n",
      " 영원히 변할 것 같지 않던 사랑이 변하고, 그 사실을 받아들이지 못하는 상우는 어찌 할 바를 모른다.\n",
      " 은수를 잊지 못하는 상우는 미련과 집착의 감정을 이기지 못하고 서울과 강릉을 오간다.\n",
      "유사 이래 연령, 성별, 빈부의 차이와 정치적인 입장을 불문하고 일거에 국민을 통합해 온 '애국심'이라는 성역에 일침을 가하는 다큐멘터리. 재작년 전국 민족민주 유가족협의회의 장기농성을 다룬 인상적인 다큐멘터리 <민들레>를 만들었던 독립영화집단 '빨간 눈사람'이 우리 사회 구석구석을 발빠르게 돌아다니며 애국심과 민족주의가 강요되는 현장을 발굴하여 카메라에 담았다. 박홍 서강대 명예총장, 이도형 '한국논단' 발행인, 축구해설자 신문선, 홍세화, 박노해 등 사회 각계의 '스타'들이 등장해 저마다의 확고한 신념을 성토한다. 감독 이경순과 최하동하는 이 작품을 위해 3년간 백여 명을 인터뷰했다고 한다. 2001 올해의 독립영화상 수상.\n",
      " 민족과 국가란 공동체에서 부단히 권력과 부를 얻는 자, 나아가 민족과 국가란 공동체에서 얻은 신분과 부귀를 영원히 그의 자손에게 대물림하려는 자, 그래서 민족과 국가란 공동체를 부단히 유지해야만 하는 자, 따라서 민족과 국가란 공동체의 당위성과 개인의 가치를 초월하는 그 존엄성을 끝도 없이 창조하고 되뇌어야 하는 자, 종국에는 민족과 국가란 공동체에 속해 있다고 태내에서부터 세뇌된 모든 이들의 삶과 행동에서 영원히 자기복제되는 순환의 고리, 영생하는 애국의 원동력은 그 순환의 골에서 온다.\n",
      "엽기적인 살인사건이 발생한 장소를 관광하는 투어팀. 그 팀에서 관광객들은 살인사건과 관련하여 히스테리컬한 반응을 보이는데 과연 이들의 정체는? (Tourists see whrer a murder take place. They respond hysterically to the murder…what are they?)\n",
      " 제46회 발라돌리드 국제영화제 (2001, 스페인)\n",
      "착하지만 엉뚱한 태희(배두나 분), 예쁜 깍쟁이 혜주(이요원 분), 그림을 잘 그리는 지영(옥지영 분), 명랑한 쌍둥이 비류(이은실 분)와 온조(이은주 분)는 단짝친구들. 늘 함께였던 그들이지만 스무 살이 되면서 길이 달라진다. 증권회사에 입사한 혜주는 성공한 커리어우먼의 야심을 키우고 미술에 재능이 있는 지영은 유학을 꿈꾼다. 한편 태희는 봉사활동에서 알게 된 뇌성마비 시인을 좋아하는데...\n",
      "  어느 날 지영이 길 잃은 새끼 고양이 티티를 만남면서 스무 살 그녀들의 삶에 고양이 한 마리가 끼어들게 된다. 혼자 있길 좋아하고, 쉽게 마음을 열지 않는 신비로운 동물 고양이. 고양이를 닮은 스무 살 그녀들. 고양이 티티와 함께 한 시간동안 삶은 예상못한 방향으로 흘러가지만 마침내 그녀들만의 해결책을 찾게 되는데... 사랑스런 몽상가 태희, 아름다운 야심가 혜주, 신비로운 아웃사이더 지영. 마지막으로 고양이를 부탁받은 사람은 누구일까?\n",
      "인도 등 아시아 식민지에 처음 발을 디딘 뒤 여행하고 “경영”한 이들은 과연 누구였을까? 과거의 이미지들은, 이민과 인종 문제, ‘오리엔탈리즘’이 격렬히 충돌하고 있는 현재와 강력하게 공명한다.\n",
      " [제19회 인디다큐페스티발]\n",
      "홀로 살아가는 미국 할머니와 한국 할머니의 이야기. 공원에서 가끔 마주치게 되는 그들은 비록 언어 소통의 어려움을 겪지만 시간이 흘러감에 따라 서로 가까워져 그들의 외로움과 우정을 공유하게 된다. 겨울이 지나고 봄이 왔을 때 길가의 민들레 홀씨는 삶의 이치를 말해주듯 한 할머니의 주위를 맴돈다. (Two elderly widows, an American and a Korean, frequent the same park in Philadelphia and attempt a friendship, though the Korean widow speaks no English. Driven by loneliness and a spark of hope, they persevere within the limits of body language, and the outcome poses a question of life as fundamental as a flower.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis.txt', 'r') as file:\n",
    "    for i in range(20):\n",
    "        print(file.readline(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-belle",
   "metadata": {},
   "source": [
    "이제 synopsis.txt 파일을 읽어 품사가 명사인 경우만 남겨 tokenized라는 변수명으로 저장해봅시다.\n",
    "konlpy 패키지를 이용해봅시다.\n",
    "\n",
    "$ pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "amateur-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약 15분정도 걸립니다.\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "tokenized = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" 등을 포함할 수도 있습니다.\n",
    "                res.append(w[0])    # 명사일 때만 tokenized 에 저장하게 됩니다. \n",
    "        tokenized.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-transparency",
   "metadata": {},
   "source": [
    "2. 추출된 결과로 embedding model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# tokenized에 담긴 데이터를 가지고 나만의 Word2Vec을 생성합니다. (Gensim 4.0 기준)\n",
    "model = Word2Vec(tokenized, vector_size=100, window=5, min_count=3, sg=0)  \n",
    "model.wv.most_similar(positive=['영화'])\n",
    "\n",
    "# Gensim 3.X 에서는 아래와 같이 생성합니다. \n",
    "# model = Word2Vec(tokenized, size=100, window=5, min_count=3, sg=0)  \n",
    "# model.most_similar(positive=['영화'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-beginning",
   "metadata": {},
   "source": [
    "어떤가요? 나만의 Word2Vec이 잘 훈련된 거 같나요? 아래와 같이 좀더 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['사랑'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=['연극'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-collector",
   "metadata": {},
   "source": [
    "### 6-7. 직접 만드는 Word Embedding에 WEAT 적용(2)\n",
    "\n",
    "3. TF-IDF로 해당 데이터를 가장 잘 표현하는 단어 셋 만들기\n",
    "WEAT score를 구할 때 단어 셋을 만들어주어야 합니다.\n",
    "targets_X, targets_Y, attribute_A, attribute_B를 만들어주었던 것이 기억나시죠?\n",
    "그렇다면 우리는 두 축을 어떤 기준으로 잡고, 해당 축의 어떤 항목을 사용할지 정해야 합니다. 여기서는 두 축을 영화 장르, 영화 구분 정보를 이용하겠습니다. (영화 구분 정보란 일반영화, 예술영화, 독립영화로 구분된 정보입니다. KOBIS에서 제공한 정보를 기준으로 분류하였습니다. )\n",
    "\n",
    "\n",
    "영화 구분\n",
    "synopsis_art.txt : 예술영화\n",
    "synopsis_gen.txt : 일반영화(상업영화)\n",
    "그 외 독립영화 등으로 분류됩니다.\n",
    "\n",
    "장르 구분\n",
    "synopsis_SF.txt: SF\n",
    "synopsis_가족.txt: 가족\n",
    "synopsis_공연.txt: 공연\n",
    "synopsis_공포(호러).txt: 공포(호러)\n",
    "synopsis_기타.txt: 기타\n",
    "synopsis_다큐멘터리.txt: 다큐멘터리\n",
    "synopsis_드라마.txt: 드라마\n",
    "synopsis_멜로로맨스.txt: 멜로로맨스\n",
    "synopsis_뮤지컬.txt: 뮤지컬\n",
    "synopsis_미스터리.txt: 미스터리\n",
    "synopsis_범죄.txt: 범죄\n",
    "synopsis_사극.txt: 사극\n",
    "synopsis_서부극(웨스턴).txt: 서부극(웨스턴)\n",
    "synopsis_성인물(에로).txt: 성인물(에로)\n",
    "synopsis_스릴러.txt: 스릴러\n",
    "synopsis_애니메이션.txt: 애니메이션\n",
    "synopsis_액션.txt: 액션\n",
    "synopsis_어드벤처.txt: 어드벤처\n",
    "synopsis_전쟁.txt: 전쟁\n",
    "synopsis_코미디.txt: 코미디\n",
    "synopsis_판타지.txt: 판타지\n",
    "이번에는 예술영화와 일반영화(상업영화)라는 영화구분을 target으로 삼고, 드라마 장르와 액션 장르라는 장르구분을 attribute로 삼아 WEAT score를 계산해 보겠습니다.\n",
    "이것의 의미는, 드라마 장르에는 예술영화적 성격이 강하고, 액션 장르에는 일반(상업)영화적 성격이 강할 것이라는 편향성이 워드 임베딩 상에 얼마나 나타나고 있는지를 측정해 보겠다는 것입니다.\n",
    "\n",
    "'synopsis_art.txt', 'synopsis_gen.txt' 두 파일을 읽고, 위에서 했던 것과 마찬가지로 명사에 대해서만 추출하여 art, gen 변수에 할당하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "art_txt = 'synopsis_art.txt'\n",
    "gen_txt = 'synopsis_gen.txt'\n",
    "\n",
    "def read_token(file_name):\n",
    "    okt = Okt()\n",
    "    result = []\n",
    "    with open(os.getenv('HOME')+'/aiffel/weat/'+file_name, 'r') as fread: \n",
    "        print(file_name, '파일을 읽고 있습니다.')\n",
    "        while True:\n",
    "            line = fread.readline() \n",
    "            if not line: break \n",
    "            tokenlist = okt.pos(line, stem=True, norm=True) \n",
    "            for word in tokenlist:\n",
    "                if word[1] in [\"Noun\"]:#, \"Adjective\", \"Verb\"]:\n",
    "                    result.append((word[0])) \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 파일을 처리하는데 10분 가량 걸립니다. \n",
    "art = read_token(art_txt)\n",
    "gen = read_token(gen_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-poverty",
   "metadata": {},
   "source": [
    "WEAT 계산을 위해서는 총 4개의 단어 셋 X, Y, A, B가 필요합니다. 예를 들어, 예술영화라는 개념을 가장 잘 대표하는 단어들을 art_txt를 처리해서 만든 art라는 단어 리스트에서부터 골라내야 하는 것입니다. 이를 위해서 우리가 각자의 상식을 동원해서 적절한 단어를 골라낼 수도 있을 것입니다. 하지만 보다 납득할 수 있는 보편적인 방법을 사용하기를 바랍니다.\n",
    "\n",
    "어떤 개념을 나타내는 단어를 선정하는 방법으로 어떤 것이 적당할까요? 꼭 정해진 방법이 있는 것은 아닙니다. 그러나 이번 경우에는 예술영화, 일반영화라는 영화구분별로 시놉시스를 모아 데이터를 구성했습니다. 그렇다면 예술영화를 잘 대표하는 단어란, 예술영화 시놉시스에는 자주 나타나지만 그 외 다른 구분의 영화(예를 들어 일반영화) 시놉시스에는 자주 나타나지 않는 것을 고르는 것이 적당할 것입니다.\n",
    "\n",
    "이런 것과 비슷한 개념의 단어 분석 방식 중 TF-IDF라는 것을 이미 접해 보셨을 것입니다. 즉, 코퍼스에서 자주 나타나는(TF가 높은) 단어이지만, 다른 코퍼스에까지 두루 걸쳐 나오지는 않는(IDF가 높은) 단어를 선정하고 싶은 것입니다.\n",
    "이번에는 단어 셋 구성을 위해 TF-IDF방식을 사용하겠습니다. (그러나 이 방식이 최선이라는 것은 아닙니다.)\n",
    "\n",
    "https://wikidocs.net/31698\n",
    "\n",
    "TF-IDF에 관한 내용이 궁금하신 분은 위키독스 를 참고하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform([art, gen])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.vocabulary_['영화'])\n",
    "print(vectorizer.get_feature_names()[23976])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = X[0].tocoo()   # art를 TF-IDF로 표현한 spart matrix를 가져옵니다. \n",
    "m2 = X[1].tocoo()   # gen을 TF-IDF로 표현한 spart matrix를 가져옵니다. \n",
    "\n",
    "w1 = [[i, j] for i, j in zip(m1.col, m1.data)]\n",
    "w2 = [[i, j] for i, j in zip(m2.col, m2.data)]\n",
    "\n",
    "w1.sort(key=lambda x: x[1], reverse=True)   #art를 구성하는 단어들을 TF-IDF가 높은 순으로 정렬합니다. \n",
    "w2.sort(key=lambda x: x[1], reverse=True)   #gen을 구성하는 단어들을 TF-IDF가 높은 순으로 정렬합니다. \n",
    "\n",
    "print('예술영화를 대표하는 단어들:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w1[i][0]], end=', ')\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print('일반영화를 대표하는 단어들:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w2[i][0]], end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-halloween",
   "metadata": {},
   "source": [
    "어떤가요? 두 개념을 대표하는 단어를 TF-IDF가 높은 순으로 추출하고 싶었는데, 양쪽에 중복된 단어가 너무 많은 것을 볼 수 있습니다.\n",
    "두 개념축이 대조되도록 대표하는 단어 셋을 만들고 싶기 때문에 중복되지 않게 추출하도록 합니다.\n",
    "우선 상위 100개의 단어들 중 중복되는 단어를 제외하고 상위 n(=15)개의 단어를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "w1_, w2_ = [], []\n",
    "for i in range(100):\n",
    "    w1_.append(vectorizer.get_feature_names()[w1[i][0]])\n",
    "    w2_.append(vectorizer.get_feature_names()[w2[i][0]])\n",
    "\n",
    "# w1에만 있고 w2에는 없는, 예술영화를 잘 대표하는 단어를 15개 추출한다.\n",
    "target_art, target_gen = [], []\n",
    "for i in range(100):\n",
    "    if (w1_[i] not in w2_) and (w1_[i] in model.wv): target_art.append(w1_[i])\n",
    "    if len(target_art) == n: break \n",
    "\n",
    "# w2에만 있고 w1에는 없는, 일반영화를 잘 대표하는 단어를 15개 추출한다.\n",
    "for i in range(100):\n",
    "    if (w2_[i] not in w1_) and (w2_[i] in model.wv): target_gen.append(w2_[i])\n",
    "    if len(target_gen) == n: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-healing",
   "metadata": {},
   "source": [
    "추출된 단어를 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-diameter",
   "metadata": {},
   "source": [
    "이번에는 장르별 대표 단어를 추출해 봅시다. 이번에는 드라마 장르와 액션 장르를 다루어 보려고 합니다. 그러나 그렇다고 해서 드라마와 액션 단 2개의 장르만 고려하기보다는 여러 장르의 코퍼스를 두루 고려하는 것이 특정 장르를 대표하는 단어를 선택하는 데 더 유리할 것입니다. 이번에는 주요 장르 5개만 고려해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_txt = ['synopsis_drama.txt', 'synopsis_romance.txt', 'synopsis_action.txt', 'synopsis_comedy.txt', 'synopsis_war.txt', 'synopsis_horror.txt']\n",
    "genre_name = ['드라마', '멜로로맨스', '액션', '코미디', '전쟁', '공포(호러)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약 10분정도 걸립니다.\n",
    "genre = []\n",
    "for file_name in genre_txt:\n",
    "    genre.append(read_token(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(genre)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [X[i].tocoo() for i in range(X.shape[0])]\n",
    "\n",
    "w = [[[i, j] for i, j in zip(mm.col, mm.data)] for mm in m]\n",
    "\n",
    "for i in range(len(w)):\n",
    "    w[i].sort(key=lambda x: x[1], reverse=True)\n",
    "attributes = []\n",
    "for i in range(len(w)):\n",
    "    print(genre_name[i], end=': ')\n",
    "    attr = []\n",
    "    j = 0\n",
    "    while (len(attr) < 15):\n",
    "        if vectorizer.get_feature_names()[w[i][j][0]] in model.wv:\n",
    "            attr.append(vectorizer.get_feature_names()[w[i][j][0]])\n",
    "            print(vectorizer.get_feature_names()[w[i][j][0]], end=', ')\n",
    "        j += 1\n",
    "    attributes.append(attr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-inspector",
   "metadata": {},
   "source": [
    "각 장르를 대표하는 단어들을 추출해보았습니다. 우리가 생각했던 직관과 데이터에 있는 단어들이 잘 맞나요?\n",
    "중복된 것이 종종 있지만 art, gen 두 개의 단어 셋을 추출했을 때에 비해 적습니다. 그러므로 중복을 체크해서 삭제하기보다 그대로 사용하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-punch",
   "metadata": {},
   "source": [
    "4. embedding model과 단어 셋으로 WEAT score 구해보기\n",
    "\n",
    "이제 WEAT_score를 구해봅시다.\n",
    "traget_A는 art, target_B는 gen, attribute_X는 '드라마', attribute_Y는 '액션' 과 같이 정해줄 수 있습니다.\n",
    "\n",
    "target_A 는 art, target_B 는 gen으로 고정하고 attribute_X, attribute_Y를 바꿔가면서 구해봅시다.\n",
    "구한 결과를 21x21 매트릭스 형태로 표현해서 matrix 라는 변수에 담아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0 for _ in range(len(genre_name))] for _ in range(len(genre_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([model.wv[word] for word in target_art])\n",
    "B = np.array([model.wv[word] for word in target_gen])\n",
    "\n",
    "for i in range(len(genre_name)-1):\n",
    "    for j in range(i+1, len(genre_name)):\n",
    "        X = np.array([model.wv[word] for word in attributes[i]])\n",
    "        Y = np.array([model.wv[word] for word in attributes[j]])\n",
    "        matrix[i][j] = weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-photography",
   "metadata": {},
   "source": [
    "matrix를 채워보았습니다.\n",
    "WEAT score 값이 2와 -2에 가까운 수치들을 보고, 과연 우리의 직관과 비슷한지 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(genre_name)-1):\n",
    "    for j in range(i+1, len(genre_name)):\n",
    "        if matrix[i][j] > 1.1 or matrix[i][j] < -1.1:\n",
    "            print(genre_name[i], genre_name[j],matrix[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-michigan",
   "metadata": {},
   "source": [
    "예술영화와 일반영화, 그리고 다큐멘터리와 멜로로맨스의 WEAT score의 의미를 해석해보면 예술 영화는 멜로로맨스와 가깝고, 다큐멘터리는 일반 영화와 가깝다고 볼 수 있습니다.\n",
    "\n",
    "예술영화와 일반영화, 그리고 멜로로맨스와 전쟁의 WEAT score의 의미를 해석해보면 예술 영화는 멜로로맨스와 가깝고, 전쟁은 일반 영화와 가깝다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import seaborn as sns; \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 한글 지원 폰트\n",
    "sns.set(font=\"Noto Sans CJK JP\")\n",
    "\n",
    "ax = sns.heatmap(matrix, xticklabels=genre_name, yticklabels=genre_name, annot=True,  cmap='RdYlGn_r')\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-montreal",
   "metadata": {},
   "source": [
    "지금까지 word embedding model에 있는 편향성을 확인해보기 위해 WEAT score를 시도해보았습니다.\n",
    "이 학습을 통해 여러분이 가진 데이터로 word embedding model을 만들 수 있고, 이 모델이 특정 분야에 대해 편향이 되어있는지 확인해볼 수 있게 되었기를 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-spirit",
   "metadata": {},
   "source": [
    "### 6-8. 프로젝트 : 모든 장르 간 편향성 측정해 보기\n",
    "\n",
    "지금까지 우리는 영화 시놉시스 코퍼스를 가지고 영화 구분과 영화 장르 간에 내재된 편향성을 측정하는 작업을 진행해 보았습니다. 어느 정도는 우리의 상식과 일치하는 편향성이 측정되었을 것입니다.\n",
    "\n",
    "이번에는 모든 장르에 대해 영화 구분과의 편향성 정도를 측정해 보겠습니다. 대부분의 과정은 이전 스텝에서 이미 진행한 내용을 참고해서 동일하게 진행 가능할 것입니다.\n",
    "\n",
    "#### STEP 1. 형태소 분석기를 이용하여 품사가 명사인 경우 해당 단어를 추출하기\n",
    "\n",
    "#### STEP 2. 추출된 결과로 embedding model 만들기\n",
    "\n",
    "#### STEP 3. target, attribute 단어 셋 만들기\n",
    "\n",
    "이전 스텝에서는 TF-IDF를 사용해서 단어 셋을 만들었습니다. 이 방법으로도 어느 정도는 대표 단어를 잘 선정할 수 있습니다. 그러나 TF-IDF가 높은 단어를 골랐음에도 불구하고 중복되는 단어가 발생하는 문제가 있었습니다.\n",
    "개념축을 표현하는 단어가 제대로 선정되지 않은 것은 WEAT 계산 결과에 악영향을 미칩니다.\n",
    "\n",
    "혹시 TF-IDF를 적용했을 때의 문제점이 무엇인지 지적 가능하다면 그 문제점을 지적하고 스스로 방법을 개선하여 대표 단어 셋을 구축해 보기 바랍니다. TF-IDF 방식을 쓰더라도 중복된 단어를 잘 제거하면 여전히 유용한 방식이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_txt = ['synopsis_SF.txt', 'synopsis_family.txt', 'synopsis_show.txt', 'synopsis_horror.txt', 'synopsis_etc.txt', \n",
    "             'synopsis_documentary.txt', 'synopsis_drama.txt', 'synopsis_romance.txt', 'synopsis_musical.txt', \n",
    "             'synopsis_mystery.txt', 'synopsis_crime.txt', 'synopsis_historical.txt', 'synopsis_western.txt', \n",
    "             'synopsis_adult.txt', 'synopsis_thriller.txt', 'synopsis_animation.txt', 'synopsis_action.txt', \n",
    "             'synopsis_adventure.txt', 'synopsis_war.txt', 'synopsis_comedy.txt', 'synopsis_fantasy.txt']\n",
    "genre_name = ['SF', '가족', '공연', '공포(호러)', '기타', '다큐멘터리', '드라마', '멜로로맨스', '뮤지컬', '미스터리', '범죄', '사극', '서부극(웨스턴)',\n",
    "         '성인물(에로)', '스릴러', '애니메이션', '액션', '어드벤처', '전쟁', '코미디', '판타지']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-programmer",
   "metadata": {},
   "source": [
    "#### STEP 4. WEAT score 계산과 시각화\n",
    "\n",
    "영화 구분, 영화 장르에 따른 편향성을 측정하여 WEAT score로 계산해 보고 이를 Heatmap 형태로 시각화해 봅시다. 편향성이 두드러지는 영화장르 attribute 구성에는 어떤 케이스가 있는지 시각적으로 두드러지게 구성되면 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-pottery",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "\n",
    "1. 주어진 영화 코퍼스를 바탕으로 워드임베딩 모델을 정상적으로 만들었다.\n",
    "\n",
    "워드임베딩의 most_similar() 메소드 결과가 의미상 바르게 나왔다.\n",
    "\n",
    "2. 영화 구분, 장르별로 target, attribute에 대한 대표성있는 단어 셋을 생성하였다.\n",
    "\n",
    "타당한 방법론을 통해 중복이 잘 제거되고 개념축을 의미적으로 잘 대표하는 단어 셋이 만들어졌다.\n",
    "\n",
    "3. WEAT score 계산 및 시각화를 정상적으로 진행하였다.\n",
    "\n",
    "전체 영화 장르별로 예술/일반 영화에 대한 편향성 WEAT score가 상식에 부합하는 수치로 얻어졌으며 이를 잘 시각화하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel-nlp",
   "language": "python",
   "name": "aiffel-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
