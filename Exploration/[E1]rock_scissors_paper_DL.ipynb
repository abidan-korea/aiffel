{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위바위보 이미지를 딥러닝 학습시키기\n",
    "\n",
    "\n",
    "## *목차\n",
    "\n",
    "\n",
    "#### 1.각 패키지 불러오기\n",
    "#### 2.모든 경로 설정하기\n",
    "#### 3.학습 및 테스트 데이터셋 준비, 전처리\n",
    "#### 4.딥러닝 네트워크 설계하기\n",
    "#### 5.훈련\n",
    "#### 6.추론\n",
    "#### 7.실험결과\n",
    "#### 8.결론\n",
    "#### 9.논의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 각 패키지 설치 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages (8.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow  \n",
    "from PIL import Image\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모든 경로 설정하기\n",
    "\n",
    "##### ubuntu home path : ubuntu home 의 경로\n",
    "##### train images path : 학습 이미지들의 경로\n",
    "##### test images path : 테스트 이미지들의 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubuntu_home_path = os.getenv(\"HOME\")   # ./home/aiffel\n",
    "train_images_path = ubuntu_home_path + \"/aiffel/exp1_rock_scissor_paper/images/rock_scissor_paper_train\"\n",
    "test_images_path = ubuntu_home_path + \"/aiffel/exp1_rock_scissor_paper/images/rock_scissor_paper_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.학습 및 테스트 데이터셋 준비, 전처리\n",
    "#### 1)이미지 촬영 및 다운로드 (https://teachablemachine.withgoogle.com/), 경로설정\n",
    "#### 2)학습이미지 resize(224x224x3 >> 28x28x3)\n",
    "#### 3)학습이미지  label(0/1/2), 메모리 올리기\n",
    "#### 4)이미지 normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize finished\n"
     ]
    }
   ],
   "source": [
    "# 2) 학습이미지 resize\n",
    "\n",
    "# 1 장의 이미지를 resize 하는 함수\n",
    "def resize_image(img):\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "\n",
    "target_size=(28,28)  # 28*28로 resize\n",
    "directories = ['rock', 'scissor', 'paper']  # 3개 폴더 모두 적용\n",
    "\n",
    "# 가위 바위 보 3 폴더에 대해서 resize 진행\n",
    "for dir in directories:   # rock, scissor, paper 3개 폴더에 대해서\n",
    "    images = glob.glob(train_images_path + \"/\" + dir + \"/*.jpg\")  # 폴더 안의 모든 사진을\n",
    "    for img in images:\n",
    "        resize_image(img)   # resize\n",
    "print(\"rock scissor paper resize finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 학습 이미지 label, x_train, y_train 설정\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_norm shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# 4) 이미지 올리기, normalize\n",
    "\n",
    "# x_train, y_train 설정\n",
    "(x_train, y_train)=load_data(train_images_path)\n",
    "# x_train normalize\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  2\n",
      "[[107 106 111]\n",
      " [109 107 110]\n",
      " [110 108 111]\n",
      " [114 108 110]\n",
      " [119 110 113]\n",
      " [124 112 114]\n",
      " [130 114 115]\n",
      " [135 114 113]\n",
      " [106  80  79]\n",
      " [ 86  56  54]\n",
      " [100  66  64]\n",
      " [ 84  46  43]\n",
      " [ 99  58  54]\n",
      " [100  56  53]\n",
      " [ 94  49  44]\n",
      " [ 94  49  44]\n",
      " [ 90  55  61]\n",
      " [134 102 107]\n",
      " [160 131 135]\n",
      " [148 126 128]\n",
      " [155 139 139]\n",
      " [123 113 111]\n",
      " [126 122 119]\n",
      " [140 141 136]\n",
      " [138 143 137]\n",
      " [137 142 138]\n",
      " [135 140 136]\n",
      " [133 138 134]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image test\n",
    "\n",
    "n = 210\n",
    "\n",
    "plt.imshow(x_train[n])\n",
    "print('라벨: ', y_train[n])\n",
    "print(x_train[n][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d98e54d3e69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'라벨: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_norm' is not defined"
     ]
    }
   ],
   "source": [
    "# norm image test\n",
    "\n",
    "n = 100\n",
    "\n",
    "plt.imshow(x_train_norm[n])\n",
    "print('라벨: ', y_train[n])\n",
    "print(x_train_norm[n][14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 딥러닝 네트워크 설계\n",
    "#### MNIST 와 동일하나, hyperparameter 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 29,795\n",
      "Trainable params: 29,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1 = 16\n",
    "n_channel_2 = 32    # \n",
    "n_dense = 32   # \n",
    "n_train_epoch = 10\n",
    "input_image_shape = (28,28,3)  # rgb 3 channel\n",
    "classes_number = 3  # rock scissor paper\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=input_image_shape))\n",
    "model.add(keras.layers.MaxPool2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(classes_number, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0760 - accuracy: 0.4500\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8773 - accuracy: 0.7100\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7105 - accuracy: 0.7967\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.8533\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8733\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8733\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8867\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe11032b5d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 이미지 디렉토리 경로:  /home/aiffel/aiffel/exp1_rock_scissor_paper/images/rock_scissor_paper_test\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "x_test_norm shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# test image dataset 세팅\n",
    "\n",
    "print(\"test 이미지 디렉토리 경로: \", test_images_path)\n",
    "(x_test, y_test)=load_data(test_images_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.0939 - accuracy: 0.3667\n",
      "test_loss: 2.0939366817474365 \n",
      "test_accuracy: 0.36666667461395264\n"
     ]
    }
   ],
   "source": [
    "# Test 진행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.결과\n",
    "\n",
    "\n",
    "#### 1) 학습 데이터셋의 양 (2000 vs 100)\n",
    "1-1)\n",
    "1-2)\n",
    "\n",
    "#### 2) 학습 이미지 해상도(224 vs 28)\n",
    "2-1)\n",
    "2-2)\n",
    "\n",
    "#### 3) normalize vs non-normalize\n",
    "3-1)\n",
    "3-2)\n",
    "\n",
    "\n",
    "// 2000 vs 100\n",
    "\n",
    "// 224 vs 28 \n",
    "\n",
    "// normalize 한 경우\n",
    "1.내 사진(각100)으로 학습, 보배님 사진(각100)으로 test\n",
    " : accuracy 0.367\n",
    "2.다운로드 사진(각2000)으로 학습, 내 사진(각100)으로 test\n",
    " : accuracy \n",
    " \n",
    " \n",
    "// normalize 하지 않았을 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.결론\n",
    "\n",
    "##### 1.학습 데이터셋의 양이 증가함에 따라, 학습 성능이 증가한다.\n",
    "##### 2.학습 데이터셋의 해상도가 증가함에 따라, 학습 성능이 증가한다.\n",
    "##### 3.학습 시, 다양한 데이터 셋을 normalize 하여 학습함에 따라, 학습 성능이 증가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.논의\n",
    "\n",
    "#### 1.과연 가위바위보를 분류하는데 딥러닝을 적용하는게 맞는 것일까?\n",
    "손을 인식하기 위한 딥러닝 분류를 적용하는 것은 맞다고 맞다.\n",
    "그런데 어찌보면 가위바위보는 손가락 숫자를 counting 하는 것이다\n",
    "어떤 사람은 가위를 엄지/검지로 하고 어떤 사람은 검지/중지로 한다.\n",
    "손을 인식하고, 해당 box 안에 손가락을 counting 하는 것은 다른 기존의 영상처리법으로 하는게 낫지 않을까??\n",
    "\n",
    "\n",
    "#### 2.손 사진을 28 * 28 * 3 으로 resize/reshape 하는 것이 적절할까?\n",
    "resize 사진을 보면 사람도 구분하기 애매한 것들이 많다.\n",
    "오리지날 image가 224 * 224 * 3 이니까 정도면 직접 학습하면 어떨까? 학습시간은 오래걸리겠지만 성능은 낫지 않을까\n",
    "\n",
    "\n",
    "#### 3.이미지 레이블 박스 처리를 해줬어야하지 않나?\n",
    "손 사진을 학습시킬때, 사실 28*28 모든 픽셀을 학습에 사용하였지만, 실제 손 사진은 \n",
    "즉, 이미지 레이블 박스를 치지 않았다.\n",
    "이 과정에서 훈련 데이터 셋이 전처리가 깔끔하게 되었다고 보기 힘들다.\n",
    "\n",
    "#### 4.normalize 할때 255 로 나누기만 하면 될까?\n",
    "이미지 내 최대 밝기/최소밝기가 있다면, max>>1, min>>0 사이의 값으로 normalize하는게 맞지 않을까"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
